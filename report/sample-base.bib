@book{grooten2018living,
  title={Living planet report-2018: aiming higher.},
  author={Grooten, Monique and Almond, Rosamunde EA and others},
  year={2018},
  publisher={WWF international}
}

@InProceedings{Redmon_2016_CVPR,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
title = {You Only Look Once: Unified, Real-Time Object Detection},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{naqvi2022camera,
  title={Camera traps are an effective tool for monitoring insect--plant interactions},
  author={Naqvi, Qaim and Wolff, Patrick J and Molano-Flores, Brenda and Sperry, Jinelle H},
  journal={Ecology and Evolution},
  volume={12},
  number={6},
  pages={e8962},
  year={2022},
  publisher={Wiley Online Library}
}

@article{ratnayake2021tracking,
  title={Tracking individual honeybees among wildflower clusters with computer vision-facilitated pollinator monitoring},
  author={Ratnayake, Malika Nisal and Dyer, Adrian G and Dorin, Alan},
  journal={Plos one},
  volume={16},
  number={2},
  pages={e0239504},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{ratnayake2021towards,
  title={Towards computer vision and deep learning facilitated pollination monitoring for agriculture},
  author={Ratnayake, Malika Nisal and Dyer, Adrian G and Dorin, Alan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2921--2930},
  year={2021}
}

@article{wang2024yolov9,
  title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information},
  author={Wang, Chien-Yao and Yeh, I-Hau and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2402.13616},
  year={2024}
}

@article{fukushima1980neocognitron,
  title={Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Fukushima, Kunihiko},
  journal={Biological cybernetics},
  volume={36},
  number={4},
  pages={193--202},
  year={1980},
  publisher={Springer}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@inproceedings{wang2023yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7464--7475},
  year={2023}
}

@article{ollerton2011many,
  title={How many flowering plants are pollinated by animals?},
  author={Ollerton, Jeff and Winfree, Rachael and Tarrant, Sam},
  journal={Oikos},
  volume={120},
  number={3},
  pages={321--326},
  year={2011},
  publisher={Wiley Online Library}
}
@InProceedings{Peng_2018_CVPR,
author = {Peng, Chao and Xiao, Tete and Li, Zeming and Jiang, Yuning and Zhang, Xiangyu and Jia, Kai and Yu, Gang and Sun, Jian},
title = {MegDet: A Large Mini-Batch Object Detector},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@article{gallai2009economic,
  title={Economic valuation of the vulnerability of world agriculture confronted with pollinator decline},
  author={Gallai, Nicola and Salles, Jean-Michel and Settele, Josef and Vaissi{\`e}re, Bernard E},
  journal={Ecological economics},
  volume={68},
  number={3},
  pages={810--821},
  year={2009},
  publisher={Elsevier}
}

@article{eilers2011contribution,
  title={Contribution of pollinator-mediated crops to nutrients in the human food supply},
  author={Eilers, Elisabeth J and Kremen, Claire and Smith Greenleaf, Sarah and Garber, Andrea K and Klein, Alexandra-Maria},
  journal={PLoS one},
  volume={6},
  number={6},
  pages={e21363},
  year={2011},
  publisher={Public Library of Science San Francisco, USA}
}

@article{sanchez2019worldwide,
  title={Worldwide decline of the entomofauna: A review of its drivers},
  author={S{\'a}nchez-Bayo, Francisco and Wyckhuys, Kris AG},
  journal={Biological conservation},
  volume={232},
  pages={8--27},
  year={2019},
  publisher={Elsevier}
}
@article{CHERNOV2015328,
title = {Integer-based accurate conversion between RGB and HSV color spaces},
journal = {Computers \& Electrical Engineering},
volume = {46},
pages = {328-337},
year = {2015},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2015.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0045790615002827},
author = {Vladimir Chernov and Jarmo Alander and Vladimir Bochko},
keywords = {HSV, RGB, Integer algorithm, Color space conversion},
abstract = {This paper introduces a new fast integer-based algorithm to convert the RGB color representation to HSV and vice versa. The proposed algorithm is as accurate as the classical real-valued one. The use of only integer operations increases performance and portability. Performance measurement results show a speed gain of about two times when compared with the classical C++ language implementation on PC platforms. Lookup tables are not involved, thus the memory usage is minimal. The resulting HSV color can be packed into 48 bits. The proposed method can safely replace the commonly used floating-point implementation.}
}

@InProceedings{Gebauer_2024_WACV,
    author    = {Gebauer, Eike and Thiele, Sebastian and Ouvrard, Pierre and Sicard, Adrien and Risse, Benjamin},
    title     = {Towards a Dynamic Vision Sensor-Based Insect Camera Trap},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2024},
    pages     = {7157-7166}
}
@article{bradski2000opencv,
  title={The openCV library.},
  author={Bradski, Gary},
  journal={Dr. Dobb's Journal: Software Tools for the Professional Programmer},
  volume={25},
  number={11},
  pages={120--123},
  year={2000},
  publisher={Miller Freeman Inc.}
}

@article{zhang2000flexible,
  title={A flexible new technique for camera calibration},
  author={Zhang, Zhengyou},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={22},
  number={11},
  pages={1330--1334},
  year={2000},
  publisher={IEEE}
}
@article{glasbey1998review,
  title={A review of image-warping methods},
  author={Glasbey, Chris A and Mardia, Kantilal Vardichand},
  journal={Journal of applied statistics},
  volume={25},
  number={2},
  pages={155--171},
  year={1998},
  publisher={Taylor \& Francis}
}

@article{thiele2021towards,
    author = {Thiele, Sebastian and Haalck, Lars and Struffert, Marvin and Scherber, Christoph and Risse, Benjamin },
    title = {Towards Visual Insect Camera Traps},
    journal = {International Conference on
Pattern Recognition (ICPR) Visual observation and analysis of Vertebrate And Insect Behavior Workshop},
    year = 2021 
}
@inproceedings{delbruck2016neuromorophic,
  title={Neuromorophic vision sensing and processing},
  author={Delbruck, Tobi},
  booktitle={2016 46Th european solid-state device research conference (ESSDERC)},
  pages={7--14},
  year={2016},
  organization={IEEE}
}

@unpublished{scharf2023TEMP,
  author = {Scharf, Paula},
  title  = {Monitoring of insects in the wild: Investigating the feasibility of machine learning based tiny object detection in time-lapse video recordings},
  note = {"Master Thesis"},
  month = 3,
  year = {2023},
 annote = {(Unpublished)}
}
@article{aghdam2017guide,
  title={Guide to convolutional neural networks},
  author={Aghdam, Hamed Habibi and Heravi, Elnaz Jahani and others},
  journal={New York, NY: Springer},
  volume={10},
  number={978-973},
  pages={51},
  year={2017},
  publisher={Springer}
}
@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={88},
  pages={303--338},
  year={2010},
  publisher={Springer}
}
@book{szeliski2022computer,
  title={Computer vision: algorithms and applications},
  author={Szeliski, Richard},
  year={2022},
  publisher={Springer Nature}
}

@article{dietrich1998approximate,
    author = {Dietterich, Thomas G.},
    title = "{Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms}",
    journal = {Neural Computation},
    volume = {10},
    number = {7},
    pages = {1895-1923},
    year = {1998},
    month = {10},
    abstract = "{This article reviews five approximate statistical tests for determining whether one learning algorithm outperforms another on a particular learning task. These test sare compared experimentally to determine their probability of incorrectly detecting a difference when no difference exists (type I error). Two widely used statistical tests are shown to have high probability of type I error in certain situations and should never be used: a test for the difference of two proportions and a paired-differences t test based on taking several random train-test splits. A third test, a paired-differences t test based on 10-fold cross-validation, exhibits somewhat elevated probability of type I error. A fourth test, McNemar's test, is shown to have low type I error. The fifth test is a new test, 5 × 2 cv, based on five iterations of twofold cross-validation. Experiments show that this test also has acceptable type I error. The article also measures the power (ability to detect algorithm differences when they do exist) of these tests. The cross-validated t test is the most powerful. The 5×2 cv test is shown to be slightly more powerful than McNemar's test. The choice of the best test is determined by the computational cost of running the learning algorithm. For algorithms that can be executed only once, Mc-Nemar's test is the only test with acceptable type I error. For algorithms that can be executed 10 times, the 5 × 2 cv test is recommended, because it is slightly more powerful and because it directly measures variation due to the choice of training set.}",
    issn = {0899-7667},
    doi = {10.1162/089976698300017197},
    url = {https://doi.org/10.1162/089976698300017197},
    eprint = {https://direct.mit.edu/neco/article-pdf/10/7/1895/814002/089976698300017197.pdf},
}
@article{raschka2018model,
  title={Model evaluation, model selection, and algorithm selection in machine learning},
  author={Raschka, Sebastian},
  journal={arXiv preprint arXiv:1811.12808},
  year={2018}
}


